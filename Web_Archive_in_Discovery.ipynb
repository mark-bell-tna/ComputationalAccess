{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Archive in Discovery.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7lIvMoa5LbX2jMeJ1OtFM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mark-bell-tna/ComputationalAccess/blob/main/Web_Archive_in_Discovery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5zxWUT8tqwR"
      },
      "source": [
        "import requests;      #used for connecting to the API\n",
        "import sys\n",
        "from time import sleep\n",
        "from math import log\n",
        "import os\n",
        "from urllib.request import urlopen\n",
        "import re\n",
        "import testlibrary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IibyqkbZBzk"
      },
      "source": [
        "MTC = MyTestClass(\"WebArchive\")\r\n",
        "MTC.printtext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI50nQ8OtlpS"
      },
      "source": [
        "PAGE_LIMIT = 200  # Avoid hitting the API too hard\n",
        "TOTAL_LIMIT = 500\n",
        "\n",
        "# Select fields to extract from catalogue\n",
        "# List of fields, but use a list to signify nested attributes\n",
        "# e.g. the description field is within the scopeContent field [\"scopeContent\", \"description\"]\n",
        "field_list = [\"id\",\"coveringDates\",\"description\", \"reference\", \"title\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkUAodq9KpA4"
      },
      "source": [
        "def disco_search(field_list, page_limit=100, total_limit=1000):\n",
        "    # Searches only for \"web archive\" but could be parameterised to build search string\n",
        "    myparams={\"limit\":page_limit, \"batchStartMark\":\"*\"}\n",
        "    headers={\"Accept\": \"application/json\"}; #we want the API to return data in JSON format\n",
        "    page = 0\n",
        "    retrieved = 0\n",
        "    out_results = []\n",
        "    while retrieved < total_limit:\n",
        "        page += 1\n",
        "        url = \"https://discovery.nationalarchives.gov.uk/API/search/records?sps.searchQuery=%22web%20archive%22&sps.page=\" + str(page) + \"&sps.resultsPageSize=\" + str(page_limit)\n",
        "        s=requests.Session(); #creating a session just groups the set of requests together\n",
        "        r=s.get(url, headers=headers, params=myparams); #send the url with our added parameters, call the response \"r\"\n",
        "        r.raise_for_status(); #This checks that we received an http status 200 for the server response\n",
        "        #so we know nothing's gone wrong with the call (if something has gone wrong we'd get a 404 or 500 error for example)\n",
        "        rjson=r.json()\n",
        "        if page == 1:\n",
        "            print(\"Total count:\",rjson[\"count\"])\n",
        "            print(rjson[\"records\"][0])\n",
        "\n",
        "        retrieved += len(rjson[\"records\"])\n",
        "        if len(rjson[\"records\"]) == 0:\n",
        "            break\n",
        "        for rj in rjson[\"records\"]:\n",
        "            fields = [rj[x] for x in field_list]\n",
        "            out_results.append(fields)\n",
        "    print(\"Pages:\",page)\n",
        "    print(\"Total records retrieved:\", retrieved)\n",
        "    return out_results\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khry06Y0Vjsy",
        "outputId": "b0fc5ee0-5ac1-4542-f111-6018516485b2"
      },
      "source": [
        "search_results = disco_search(field_list, page_limit = PAGE_LIMIT, total_limit = TOTAL_LIMIT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total count: 4851\n",
            "{'altName': '', 'places': [], 'corpBodies': [], 'taxonomies': [], 'formerReferenceDep': '', 'formerReferencePro': 'See Annual Return 2013', 'heldBy': ['Parliamentary Archives'], 'context': '', 'content': '', 'urlParameters': '', 'department': '', 'note': '', 'adminHistory': '', 'arrangement': '', 'mapDesignation': '', 'mapScale': '', 'physicalCondition': '', 'catalogueLevel': 0, 'openingDate': '', 'closureStatus': '', 'closureType': '', 'closureCode': '', 'documentType': '', 'coveringDates': '2009-2012', 'description': 'Bicameral Records of Parliament: records of Parliamentary Web Archive', 'endDate': '31/12/2012', 'numEndDate': 20121231, 'numStartDate': 20090101, 'startDate': '01/01/2009', 'id': 'N14203445', 'reference': 'PARL/WEB/1', 'score': 0.8886901, 'source': '300', 'title': 'Houses of Parliament, Bicameral Records of Parliament: records of Parliamentary Web Archive'}\n",
            "Pages: 3\n",
            "Total records retrieved: 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcZeGvT6Vlvj",
        "outputId": "d06b4d87-e95c-489d-8da0-890709b6f908"
      },
      "source": [
        "search_results[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C14215037',\n",
              " '2000 Jan 1 - 2000 Dec 31; 2013',\n",
              " 'Website of re-opened formal investigation. [Please Note: These digital records are presented via the UK Government Web Archive ].',\n",
              " 'MT 205/3',\n",
              " 'Website of re-opened formal investigation. [Please Note: These digital records are presented via the UK...']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxys0PcahYPW"
      },
      "source": [
        "def get_ancestors(disco_id, s=requests.Session()):\n",
        "    G = nx.DiGraph()\n",
        "    G = {}\n",
        "    headers={\"Accept\": \"application/json\"}; #we want the API to return data in JSON format\n",
        "    page = 0\n",
        "    retrieved = 0\n",
        "    out_results = []\n",
        "    url = \"https://discovery.nationalarchives.gov.uk/API/records/context/\" + disco_id\n",
        "    #s=requests.Session(); #creating a session just groups the set of requests together\n",
        "    r=s.get(url, headers=headers); #send the url with our added parameters, call the response \"r\"\n",
        "    r.raise_for_status(); #This checks that we received an http status 200 for the server response\n",
        "    #so we know nothing's gone wrong with the call (if something has gone wrong we'd get a 404 or 500 error for example)\n",
        "    rjson=r.json()\n",
        "    #print(rjson)\n",
        "    for rj in rjson:\n",
        "        G[rj['id']] = rj['parentId']\n",
        "\n",
        "    more = True\n",
        "    node = disco_id\n",
        "    ancestor_tree = []\n",
        "    while more:\n",
        "        if node not in G:\n",
        "            more = False\n",
        "            continue\n",
        "        ancestor = G[node]\n",
        "        if ancestor == None:\n",
        "            more = False\n",
        "            continue\n",
        "        ancestor_tree.append(ancestor)\n",
        "        node = ancestor\n",
        "        \n",
        "    return ancestor_tree\n",
        "\n",
        "ancestors = get_ancestors('C17172')\n",
        "print(get_ancestors('N14203445'))\n",
        "print(ancestors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVFiy-bXh9ix"
      },
      "source": [
        "# Target format:\n",
        "#{\"name\":\"flare.animate.interpolate.ArrayInterpolator\",\"size\":1983,\"imports\":[\"flare.util.Arrays\",\"flare.animate.interpolate.Interpolator\"]}\n",
        "# Source data format:\n",
        "#['C17172', 'From 2006', \n",
        "#\"This series contains dated gathered versions (or 'snapshots') of the Security Vetting Appeals Panel website. [Please note: These records may be accessed via the UK Government Web Archive ].\",\n",
        "# 'DEFE 147', 'Security Vetting Appeals Panel Website']\n",
        "#myjson_file.write(\"[\\n\")\n",
        "rows = 0\n",
        "data = disco_search(field_list, page_limit = 100, total_limit = 500)\n",
        "s=requests.Session()\n",
        "tree = {}\n",
        "for d in data:\n",
        "#    if rows > 0:\n",
        "#        myjson_file.write(\",\\n\")\n",
        "    rows += 1\n",
        "    if rows % 100 == 0:\n",
        "        print(\"Rows:\", rows)\n",
        "    disco_id = d[0]\n",
        "    title = d[4]\n",
        "    #get_ancestors(disco_id, s)\n",
        "    #print(disco_id)\n",
        "    ancestors = get_ancestors(disco_id)\n",
        "    ancestors += ['UK']\n",
        "    ancestors.reverse()\n",
        "    ancestors += [disco_id]\n",
        "    #print(ancestors)\n",
        "    this_dict = tree\n",
        "    #break\n",
        "    for anc in ancestors:\n",
        "        if anc not in this_dict:\n",
        "            this_dict[anc] = {}\n",
        "        this_dict = this_dict[anc]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}